{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Predicting Bike Rentals\n",
    "\n",
    "## 1: Introduction To The Data Set\n",
    "Many American cities have communal bike sharing stations where you can rent bicycles by the hour or day. Washington, D.C. is one of these cities. The District collects detailed data on the number of bicycles people rent by the hour and day.\n",
    "\n",
    "[Hadi Fanaee-T](http://www.liaad.up.pt/area/fanaee) at the [University of Porto](http://www.up.pt/) compiled this data into a CSV file, which we will be working with in this project. The file contains 17380 rows, with each row representing the number of bike rentals for a single hour of a single day. The data can be downloaded from the [University of California, Irvine's website](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset). \n",
    "\n",
    "Here are the descriptions for the relevant columns:\n",
    "\n",
    "* `instant` - A unique sequential ID number for each row\n",
    "* `dteday` - The date of the rentals\n",
    "* `season` - The season in which the rentals occurred\n",
    "* `yr` - The year the rentals occurred\n",
    "* `mnth` - The month the rentals occurred\n",
    "* `hr` - The hour the rentals occurred\n",
    "* `holiday` - Whether or not the day was a holiday\n",
    "* `weekday` - Whether or not the day was a weekday\n",
    "* `workingday` - Whether or not the day was a working day\n",
    "* `weathersit` - The weather (as a categorical variable)\n",
    "* `temp` - The temperature, on a `0-1` scale\n",
    "* `atemp` - The adjusted temperature\n",
    "* `hum` - The humidity, on a `0-1` scale\n",
    "* `windspeed` - The wind speed, on a `0-1` scale\n",
    "* `casual` - The number of casual riders (people who hadn't previously signed up with the bike sharing program)\n",
    "* `registered` - The number of registered riders (people who had already signed up)\n",
    "* `cnt` - The total number of bike rentals (`casual` + `registered`)\n",
    "\n",
    "In this project, we will try to predict the total number of bikes people rented in a given hour. We will predict the `cnt` column using all of the other columns, except for `casual` and `registered`. To accomplish this, we will create a few different machine learning models and evaluate their performance.\n",
    "\n",
    "* Read `bike_rental_hour.csv` into the dataframe `bike_rentals`.\n",
    "* Print out the first few rows of `bike_rentals` and take a look at the data.\n",
    "* Make a histogram of the `cnt` column of `bike_rentals`, and take a look at the distribution of total rentals.\n",
    "* Explore how each column is correlated with `cnt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
      "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
      "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
      "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
      "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bike_rentals = pd.read_csv(\"data/bike_rental_hour.csv\")\n",
    "print(bike_rentals.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAFkCAYAAACAUFlOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMnxIkqSq/j/U4PfwvFSRiAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x277c4c9a2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(bike_rentals[\"cnt\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       0.278379\n",
       "season        0.178056\n",
       "yr            0.250495\n",
       "mnth          0.120638\n",
       "hr            0.394071\n",
       "holiday      -0.030927\n",
       "weekday       0.026900\n",
       "workingday    0.030284\n",
       "weathersit   -0.142426\n",
       "temp          0.404772\n",
       "atemp         0.400929\n",
       "hum          -0.322911\n",
       "windspeed     0.093234\n",
       "casual        0.694564\n",
       "registered    0.972151\n",
       "cnt           1.000000\n",
       "Name: cnt, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_rentals.corr()[\"cnt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Calculating Features\n",
    "The `hr` column in `bike_rentals` contains the hours during which bikes are rented, from `1` to `24`. A machine will treat each hour differently, without understanding that certain hours are related. We can introduce some order into the process by creating a new column with labels for `morning`, `afternoon`, `evening`, and `night`. This will bundle similar times together, enabling the model to make better decisions.\n",
    "\n",
    "* Write a function called `assign_label` that takes in a numeric value for an hour, and returns:\n",
    "  * `1` if the hour is from `6` to `12`\n",
    "  * `2` if the hour is from `12` to `18`\n",
    "  * `3` if the hour is from `18` to `24`\n",
    "  * `4` if the hour is from `0` to `6`\n",
    "* Apply the function to each item in the `hr` column.\n",
    "* Assign the result to the `time_label` column of `bike_rentals`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
      "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
      "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
      "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
      "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \\\n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16   \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40   \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32   \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13   \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1   \n",
      "\n",
      "   time_label  \n",
      "0           4  \n",
      "1           4  \n",
      "2           4  \n",
      "3           4  \n",
      "4           4  \n"
     ]
    }
   ],
   "source": [
    "def assign_label(hr):\n",
    "    if hr >= 6 and hr < 12:\n",
    "        return 1\n",
    "    elif hr >= 12 and hr < 18:\n",
    "        return 2\n",
    "    elif hr >= 18 and hr < 24:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "bike_rentals[\"time_label\"] = bike_rentals[\"hr\"].apply(assign_label)\n",
    "print(bike_rentals.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Splitting The Data Into Train And Test Sets\n",
    "Before we begin applying machine learning algorithms, we will need to split the data into training and testing sets. This will enable us to train an algorithm using the training set, and evaluate its accuracy on the testing set.\n",
    "\n",
    "* Select 80% of the rows in `bike_rentals` to be part of the training set using the sample method on `bike_rentals`. Assign the result to `train`.\n",
    "* Select the rows that are in `bike_rentals` but not in train to be in the testing set. Assign the result to `test`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error metric\n",
    "Based on the explorations of the `cnt` column, the **mean squared error** metric makes the most sense to evaluate our error. MSE works on continuous numeric data, which fits our data quite well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13903, 18)\n"
     ]
    }
   ],
   "source": [
    "train = bike_rentals.sample(frac=.8)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3476, 18)\n"
     ]
    }
   ],
   "source": [
    "test = bike_rentals.loc[~bike_rentals.index.isin(train.index)]\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Applying Linear Regression\n",
    "Now that we have done some exploration and manipulation, we are ready to apply linear regression to the data. Linear regression will probably work fairly well on this data, given that many of the columns are highly correlated with `cnt`.\n",
    "\n",
    "We will ignore the `casual` and `registered` columns because `cnt` is derived from them. \n",
    "\n",
    "* Create a list of predictor columns to use in training and predictions.\n",
    "  * At a minimum, this list should exclude the `cnt`, `casual`, `dteday`, and `registered` columns.\n",
    "  * Remove other columns that may not be useful for the predictions.\n",
    "* Use the LinearRegression class from sklearn to train a machine learning algorithm on `train`.\n",
    "* Make predictions using the LinearRegression class on `test`.\n",
    "* Calculate the error between the predictions and the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['instant', 'dteday', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered', 'cnt', 'time_label']\n",
      "['instant', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'time_label']\n"
     ]
    }
   ],
   "source": [
    "predictors = list(train.columns)\n",
    "print(predictors)\n",
    "predictors.remove(\"dteday\")\n",
    "predictors.remove(\"casual\")\n",
    "predictors.remove(\"registered\")\n",
    "predictors.remove(\"cnt\")\n",
    "print(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17175.3838106\n",
      "131.054888541\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train[predictors], train[\"cnt\"])\n",
    "predictions = lr.predict(test[predictors])\n",
    "lr_mse = mean_squared_error(test[\"cnt\"], predictions)\n",
    "print(lr_mse)\n",
    "lr_rmse = lr_mse**(0.5)\n",
    "print(lr_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error\n",
    "The error is very high, which may be due to the fact that the data has a few extremely high rental counts, but otherwise mostly low counts. Larger errors are penalized more with MSE, which leads to a higher total error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Applying Decision Trees\n",
    "Now we will apply the decision tree algorithm. We will be able to compare its error with the error from linear regression, which will enable us to pick the right algorithm for this data set.\n",
    "\n",
    "* Use the `DecisionTreeRegressor` class to fit a decision tree algorithm to the `train` data.\n",
    "* Make predictions using the `DecisionTreeRegressor` class on `test`.\n",
    "* Calculate the error between the predictions and the actual values.\n",
    "* Experiment with various parameters of the `DecisionTreeRegressor` class, including `min_samples_leaf`, to see if it changes the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2891.4047756\n",
      "53.7717841958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(train[predictors], train[\"cnt\"])\n",
    "dt_pred = dt.predict(test[predictors])\n",
    "dt_mse = mean_squared_error(test[\"cnt\"], dt_pred)\n",
    "print(dt_mse)\n",
    "dt_rmse = dt_mse**(0.5)\n",
    "print(dt_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### varying parameter min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt 5   2322.38664163   48.1911469217\n",
      "dt 15   2893.35456634   53.7899113806\n",
      "dt 25   3254.02023327   57.0440201359\n",
      "dt 35   3726.71158682   61.0467983339\n",
      "dt 45   4015.61258567   63.3688613254\n",
      "dt 55   4295.10702288   65.5370660228\n",
      "dt 65   4472.96970499   66.8802639423\n",
      "dt 75   4593.73990477   67.7771340849\n",
      "dt 85   4785.11285979   69.1745101883\n",
      "dt 95   4998.78031093   70.7020530885\n",
      "dt 105   5850.30257292   76.4872706593\n",
      "dt 115   6458.06503624   80.3620870575\n",
      "dt 125   6727.0504161   82.0185979891\n",
      "dt 135   6848.79160262   82.7574262687\n",
      "dt 145   7154.59451042   84.584836173\n",
      "dt 155   7262.46241932   85.2200822537\n",
      "dt 165   7498.08049497   86.5914574018\n",
      "dt 175   7579.10453456   87.0580526692\n",
      "dt 185   7694.44283078   87.7179732482\n",
      "dt 195   8167.57638882   90.3746446124\n"
     ]
    }
   ],
   "source": [
    "# change parameters\n",
    "for i in range(5,200,10):\n",
    "    dt = DecisionTreeRegressor(min_samples_leaf = i)\n",
    "    dt.fit(train[predictors], train[\"cnt\"])\n",
    "    dt_pred = dt.predict(test[predictors])\n",
    "    dt_mse = mean_squared_error(test[\"cnt\"], dt_pred)\n",
    "    dt_rmse = dt_mse**(0.5)\n",
    "    print(\"dt\", i, \" \", dt_mse, \" \", dt_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with min_samples_leaf = 5 gives the least error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### varying parameter min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt 10   2596.92459347   50.9600293708\n",
      "dt 20   2436.29253477   49.3588141548\n",
      "dt 30   2541.48650734   50.4131580774\n",
      "dt 40   2627.75386803   51.2616217851\n",
      "dt 50   2691.72832145   51.8818689086\n",
      "dt 60   2811.77554754   53.0261779458\n",
      "dt 70   2849.31512871   53.3789764675\n",
      "dt 80   3003.90430416   54.8078854195\n",
      "dt 90   3102.76367725   55.7024566537\n",
      "dt 100   3218.77508029   56.7342496231\n",
      "dt 110   3295.46667525   57.4061553777\n",
      "dt 120   3375.92247159   58.102689022\n",
      "dt 130   3445.90016148   58.7017901046\n",
      "dt 140   3488.87089455   59.0666648334\n",
      "dt 150   3648.97381418   60.4067364967\n",
      "dt 160   3991.91734562   63.1816218977\n",
      "dt 170   4159.85439012   64.4969331838\n",
      "dt 180   4235.6520992   65.0818876431\n",
      "dt 190   4325.38454443   65.767655762\n"
     ]
    }
   ],
   "source": [
    "# change parameters\n",
    "for i in range(10,200,10):\n",
    "    dt = DecisionTreeRegressor(min_samples_split = i)\n",
    "    dt.fit(train[predictors], train[\"cnt\"])\n",
    "    dt_pred = dt.predict(test[predictors])\n",
    "    dt_mse = mean_squared_error(test[\"cnt\"], dt_pred)\n",
    "    dt_rmse = dt_mse**(0.5)\n",
    "    print(\"dt\", i, \" \", dt_mse, \" \", dt_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with min_samples_split = 20 gives the least error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### varying parameter max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt 2   18230.441343   135.020151618\n",
      "dt 3   15146.1030959   123.069505142\n",
      "dt 4   13155.1821973   114.69604264\n",
      "dt 5   11211.0594386   105.882290486\n",
      "dt 6   10018.2605251   100.091260983\n",
      "dt 7   6633.49242771   81.4462548415\n",
      "dt 8   4927.8883446   70.198919825\n",
      "dt 9   3924.78912468   62.6481374398\n",
      "dt 10   3315.17800755   57.5775825087\n",
      "dt 11   3119.47897089   55.8522960216\n",
      "dt 12   2821.80303433   53.1206460271\n",
      "dt 13   2771.97295594   52.649529494\n",
      "dt 14   2686.35918879   51.8300992551\n",
      "dt 15   2724.42668464   52.1960408905\n",
      "dt 16   2750.6212788   52.4463657349\n",
      "dt 17   2847.03395678   53.3576044887\n",
      "dt 18   2880.88284554   53.6738562574\n",
      "dt 19   2938.29795232   54.206069331\n"
     ]
    }
   ],
   "source": [
    "# change parameters\n",
    "for i in range(2,20):\n",
    "    dt = DecisionTreeRegressor(max_depth = i)\n",
    "    dt.fit(train[predictors], train[\"cnt\"])\n",
    "    dt_pred = dt.predict(test[predictors])\n",
    "    dt_mse = mean_squared_error(test[\"cnt\"], dt_pred)\n",
    "    dt_rmse = dt_mse**(0.5)\n",
    "    print(\"dt\", i, \" \", dt_mse, \" \", dt_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with max_depth = 14 gives the least error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### varying parameter min_samples_split while keeping max_depth at 13 and min_samples_leaf at 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt 1   2428.44784481   49.2792841345\n",
      "dt 2   2420.1104081   49.1946176741\n",
      "dt 3   2419.82762454   49.191743459\n",
      "dt 4   2427.12652093   49.2658758263\n",
      "dt 5   2432.45740434   49.3199493546\n",
      "dt 6   2426.95299538   49.2641146818\n",
      "dt 7   2430.82736875   49.303421471\n",
      "dt 8   2431.14412902   49.3066337223\n",
      "dt 9   2427.45040588   49.2691628291\n",
      "dt 10   2429.96923974   49.2947181729\n",
      "dt 11   2408.0155484   49.0715350116\n",
      "dt 12   2429.4332313   49.2892810994\n",
      "dt 13   2423.56693611   49.2297362994\n",
      "dt 14   2423.93458679   49.2334701884\n",
      "dt 15   2406.12766794   49.0522952362\n",
      "dt 16   2415.58284864   49.1485793146\n",
      "dt 17   2430.89589361   49.3041163962\n",
      "dt 18   2409.2759553   49.0843758776\n",
      "dt 19   2415.47445657   49.1474766043\n",
      "dt 20   2437.4923736   49.3709669097\n",
      "dt 21   2441.15590144   49.4080550258\n",
      "dt 22   2444.73128781   49.4442240086\n",
      "dt 23   2437.75848968   49.3736619026\n",
      "dt 24   2438.39276797   49.3800847303\n",
      "dt 25   2480.42728107   49.8038882124\n",
      "dt 26   2486.61778508   49.8659982862\n",
      "dt 27   2491.86491923   49.9185829049\n",
      "dt 28   2507.84198514   50.0783584509\n",
      "dt 29   2510.39344671   50.1038266673\n",
      "dt 30   2518.35407987   50.1832051574\n",
      "dt 31   2520.42412889   50.2038258391\n",
      "dt 32   2532.67866561   50.3257256839\n",
      "dt 33   2522.97586155   50.2292331372\n",
      "dt 34   2530.98019275   50.3088480563\n",
      "dt 35   2533.5517401   50.3343991729\n",
      "dt 36   2561.13204056   50.6076282843\n",
      "dt 37   2585.0931651   50.843811473\n",
      "dt 38   2592.94332114   50.9209516913\n",
      "dt 39   2599.24393742   50.9827807933\n",
      "dt 40   2606.04047812   51.0493925342\n",
      "dt 41   2610.64788682   51.094499575\n",
      "dt 42   2605.32731943   51.0424070693\n",
      "dt 43   2607.67139949   51.0653639906\n",
      "dt 44   2611.96352782   51.1073725388\n",
      "dt 45   2628.79884414   51.2718133495\n",
      "dt 46   2653.27032865   51.5099051509\n",
      "dt 47   2647.2533423   51.4514658907\n",
      "dt 48   2663.96777782   51.6136394553\n",
      "dt 49   2697.49265802   51.9373917137\n"
     ]
    }
   ],
   "source": [
    "# change parameters\n",
    "for i in range(1,50,1):\n",
    "    dt = DecisionTreeRegressor(max_depth = 13, min_samples_leaf = 5, min_samples_split = i)\n",
    "    dt.fit(train[predictors], train[\"cnt\"])\n",
    "    dt_pred = dt.predict(test[predictors])\n",
    "    dt_mse = mean_squared_error(test[\"cnt\"], dt_pred)\n",
    "    dt_rmse = dt_mse**(0.5)\n",
    "    print(\"dt\", i, \" \", dt_mse, \" \", dt_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with max_depth = 13, min_samples_leaf = 12 and min_samples_split = 15 gives the least error **_2406.13_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6: Applying Random Forests\n",
    "We can now apply the random forest algorithm, which improves on the decision tree algorithm. \n",
    "\n",
    "* Use the `RandomForestRegressor` class to fit a random forest algorithm to the `train` data.\n",
    "* Make predictions using the `RandomForestRegressor` class on `test`.\n",
    "* Calculate the error between the predictions and the actual values.\n",
    "* Experiment with various parameters of the `RandomForestRegressor` class, including `min_samples_leaf`, to see if it changes the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "reg = RandomForestRegressor()\n",
    "reg.fit(train[predictors], train[\"cnt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1705.348481012659"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = reg.predict(test[predictors])\n",
    "numpy.mean((predictions - test[\"cnt\"]) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest model gives lower error than the Decision Tree models.\n",
    "**_1705.35_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### varying parameter min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg 1   1748.01622842   41.809283998\n",
      "reg 2   1727.78950518   41.5666874453\n",
      "reg 3   1750.6574962   41.8408591714\n",
      "reg 4   1751.99948143   41.8568928784\n",
      "reg 5   1748.35082071   41.8132852179\n",
      "reg 6   1700.47559927   41.2368233412\n",
      "reg 7   1725.69861917   41.5415288497\n",
      "reg 8   1727.20107656   41.5596087152\n",
      "reg 9   1748.84872868   41.8192387387\n",
      "reg 10   1776.39809419   42.1473379253\n",
      "reg 11   1774.12188684   42.1203262908\n",
      "reg 12   1830.21303718   42.780989203\n",
      "reg 13   1779.93938216   42.1893278231\n",
      "reg 14   1972.8792861   44.4171057826\n",
      "reg 15   1907.55489324   43.6755640289\n",
      "reg 16   1918.3308147   43.7987535747\n",
      "reg 17   1842.63088452   42.9258766308\n",
      "reg 18   1954.9526149   44.2148460916\n",
      "reg 19   1894.18670188   43.5222552481\n",
      "reg 20   1939.19253469   44.0362638594\n",
      "reg 21   1899.24077825   43.5802796945\n",
      "reg 22   1890.85119838   43.483918848\n",
      "reg 23   2002.40888105   44.7482835543\n",
      "reg 24   1964.93543384   44.3275922405\n"
     ]
    }
   ],
   "source": [
    "# change parameters\n",
    "for i in range(1,25,1):\n",
    "    reg = RandomForestRegressor(max_depth = None, min_samples_leaf = 1, min_samples_split = i)\n",
    "    reg.fit(train[predictors], train[\"cnt\"])\n",
    "    reg_pred = reg.predict(test[predictors])\n",
    "    reg_mse = mean_squared_error(test[\"cnt\"], reg_pred)\n",
    "    reg_rmse = reg_mse**(0.5)\n",
    "    print(\"reg\", i, \" \", reg_mse, \" \", reg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with min_samples_split = 6 gives the least error **_1700.47_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### varying parameter min_samples_leaf while keeping max_depth at None and min_samples_split at 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg 1   1805.56425201   42.4919316108\n",
      "reg 2   1707.23960587   41.3187561026\n",
      "reg 3   1705.44911636   41.2970836302\n",
      "reg 4   1835.76698609   42.8458514454\n",
      "reg 5   1817.42519852   42.631270196\n",
      "reg 6   1959.09054252   44.2616147754\n",
      "reg 7   2092.73408347   45.7464106075\n",
      "reg 8   2162.33707519   46.5009362829\n",
      "reg 9   2205.57634254   46.9635639889\n",
      "reg 10   2222.86659142   47.1472861512\n",
      "reg 11   2257.15608721   47.5095368027\n",
      "reg 12   2334.96931367   48.321520192\n",
      "reg 13   2457.92898054   49.5775047833\n",
      "reg 14   2597.77657462   50.9683879932\n",
      "reg 15   2654.03617346   51.5173385712\n",
      "reg 16   2671.30347539   51.6846541576\n",
      "reg 17   2640.64782659   51.387234082\n",
      "reg 18   2843.3200758   53.3227913354\n",
      "reg 19   2804.10130941   52.9537657718\n",
      "reg 20   2798.98570464   52.9054411629\n",
      "reg 21   2982.11320566   54.6087282919\n",
      "reg 22   2998.45185067   54.7581213216\n",
      "reg 23   2934.62119976   54.1721441311\n",
      "reg 24   3097.90340106   55.6588124295\n"
     ]
    }
   ],
   "source": [
    "# change parameters\n",
    "for i in range(1,25,1):\n",
    "    reg = RandomForestRegressor(max_depth = None, min_samples_leaf = i, min_samples_split = 2)\n",
    "    reg.fit(train[predictors], train[\"cnt\"])\n",
    "    reg_pred = reg.predict(test[predictors])\n",
    "    reg_mse = mean_squared_error(test[\"cnt\"], reg_pred)\n",
    "    reg_rmse = reg_mse**(0.5)\n",
    "    print(\"reg\", i, \" \", reg_mse, \" \", reg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with min_samples_leaf = 2 gives the least error **_1707.24_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg 24   1604.11478251   40.0514017547\n"
     ]
    }
   ],
   "source": [
    "reg = RandomForestRegressor(max_depth = None, min_samples_leaf = 2, min_samples_split = 7)\n",
    "reg.fit(train[predictors], train[\"cnt\"])\n",
    "reg_pred = reg.predict(test[predictors])\n",
    "reg_mse = mean_squared_error(test[\"cnt\"], reg_pred)\n",
    "reg_rmse = reg_mse**(0.5)\n",
    "print(reg_mse, \" \", reg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varying the parameters helps lower the error even further to 1604.11. Random Forest gives much better results than the other models."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
