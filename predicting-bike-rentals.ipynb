{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Predicting Bike Rentals\n",
    "\n",
    "## 1: Introduction To The Data Set\n",
    "Many American cities have communal bike sharing stations where you can rent bicycles by the hour or day. Washington, D.C. is one of these cities. The District collects detailed data on the number of bicycles people rent by the hour and day.\n",
    "\n",
    "[Hadi Fanaee-T](http://www.liaad.up.pt/area/fanaee) at the [University of Porto](http://www.up.pt/) compiled this data into a CSV file, which we will be working with in this project. The file contains 17380 rows, with each row representing the number of bike rentals for a single hour of a single day. The data can be downloaded from the [University of California, Irvine's website](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset). \n",
    "\n",
    "Here are the descriptions for the relevant columns:\n",
    "\n",
    "* `instant` - A unique sequential ID number for each row\n",
    "* `dteday` - The date of the rentals\n",
    "* `season` - The season in which the rentals occurred\n",
    "* `yr` - The year the rentals occurred\n",
    "* `mnth` - The month the rentals occurred\n",
    "* `hr` - The hour the rentals occurred\n",
    "* `holiday` - Whether or not the day was a holiday\n",
    "* `weekday` - Whether or not the day was a weekday\n",
    "* `workingday` - Whether or not the day was a working day\n",
    "* `weathersit` - The weather (as a categorical variable)\n",
    "* `temp` - The temperature, on a `0-1` scale\n",
    "* `atemp` - The adjusted temperature\n",
    "* `hum` - The humidity, on a `0-1` scale\n",
    "* `windspeed` - The wind speed, on a `0-1` scale\n",
    "* `casual` - The number of casual riders (people who hadn't previously signed up with the bike sharing program)\n",
    "* `registered` - The number of registered riders (people who had already signed up)\n",
    "* `cnt` - The total number of bike rentals (`casual` + `registered`)\n",
    "\n",
    "In this project, we will try to predict the total number of bikes people rented in a given hour. We will predict the `cnt` column using all of the other columns, except for `casual` and `registered`. To accomplish this, we will create a few different machine learning models and evaluate their performance.\n",
    "\n",
    "* Read `bike_rental_hour.csv` into the dataframe `bike_rentals`.\n",
    "* Print out the first few rows of `bike_rentals` and take a look at the data.\n",
    "* Make a histogram of the `cnt` column of `bike_rentals`, and take a look at the distribution of total rentals.\n",
    "* Explore how each column is correlated with `cnt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
      "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
      "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
      "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
      "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bike_rentals = pd.read_csv(\"data/bike_rental_hour.csv\")\n",
    "print(bike_rentals.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAFkCAYAAACAUFlOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMnxIkqSq/j/U4PfwvFSRiAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2525106b860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(bike_rentals[\"cnt\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       0.278379\n",
       "season        0.178056\n",
       "yr            0.250495\n",
       "mnth          0.120638\n",
       "hr            0.394071\n",
       "holiday      -0.030927\n",
       "weekday       0.026900\n",
       "workingday    0.030284\n",
       "weathersit   -0.142426\n",
       "temp          0.404772\n",
       "atemp         0.400929\n",
       "hum          -0.322911\n",
       "windspeed     0.093234\n",
       "casual        0.694564\n",
       "registered    0.972151\n",
       "cnt           1.000000\n",
       "time_label   -0.378318\n",
       "Name: cnt, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_rentals.corr()[\"cnt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Calculating Features\n",
    "Features can enhance the accuracy of models by introducing new information, or distilling existing information.\n",
    "\n",
    "The `hr` column in `bike_rentals` contains the hours during which bikes are rented, from `1` to `24`. A machine will treat each hour differently, without understanding that certain hours are related. We can introduce some order into the process by creating a new column with labels for `morning`, `afternoon`, `evening`, and `night`. This will bundle similar times together, enabling the model to make better decisions.\n",
    "\n",
    "* Write a function called `assign_label` that takes in a numeric value for an hour, and returns:\n",
    "  * `1` if the hour is from `6` to `12`\n",
    "  * `2` if the hour is from `12` to `18`\n",
    "  * `3` if the hour is from `18` to `24`\n",
    "  * `4` if the hour is from `0` to `6`\n",
    "* Apply the function to each item in the `hr` column.\n",
    "* Assign the result to the `time_label` column of `bike_rentals`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
      "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
      "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
      "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
      "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \\\n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16   \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40   \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32   \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13   \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1   \n",
      "\n",
      "   time_label  \n",
      "0           4  \n",
      "1           4  \n",
      "2           4  \n",
      "3           4  \n",
      "4           4  \n"
     ]
    }
   ],
   "source": [
    "def assign_label(hr):\n",
    "    if hr >= 6 and hr < 12:\n",
    "        return 1\n",
    "    elif hr >= 12 and hr < 18:\n",
    "        return 2\n",
    "    elif hr >= 18 and hr < 24:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "bike_rentals[\"time_label\"] = bike_rentals[\"hr\"].apply(assign_label)\n",
    "print(bike_rentals.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Splitting The Data Into Train And Test Sets\n",
    "Before we begin applying machine learning algorithms, we will need to split the data into training and testing sets. This will enable us to train an algorithm using the training set, and evaluate its accuracy on the testing set.\n",
    "\n",
    "* Select 80% of the rows in `bike_rentals` to be part of the training set using the sample method on `bike_rentals`. Assign the result to `train`.\n",
    "* Select the rows that are in `bike_rentals` but not in train to be in the testing set. Assign the result to `test`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error metric\n",
    "Based on the explorations of the `cnt` column, the **mean squared error** metric makes the most sense to evaluate our error. MSE works on continuous numeric data, which fits our data quite well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13903, 18)\n"
     ]
    }
   ],
   "source": [
    "train = bike_rentals.sample(frac=.8)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3476, 18)\n"
     ]
    }
   ],
   "source": [
    "test = bike_rentals.loc[~bike_rentals.index.isin(train.index)]\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Applying Linear Regression\n",
    "Now that we have done some exploration and manipulation, we are ready to apply linear regression to the data. Linear regression will probably work fairly well on this data, given that many of the columns are highly correlated with `cnt`.\n",
    "\n",
    "We will ignore the `casual` and `registered` columns because `cnt` is derived from them. \n",
    "\n",
    "* Create a list of predictor columns to use in training and predictions.\n",
    "  * At a minimum, this list should exclude the `cnt`, `casual`, `dteday`, and `registered` columns.\n",
    "  * Remove other columns that may not be useful for the predictions.\n",
    "* Use the LinearRegression class from sklearn to train a machine learning algorithm on `train`.\n",
    "* Make predictions using the LinearRegression class on `test`.\n",
    "* Calculate the error between the predictions and the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['instant', 'dteday', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered', 'cnt', 'time_label']\n",
      "['instant', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'time_label']\n"
     ]
    }
   ],
   "source": [
    "predictors = list(train.columns)\n",
    "print(predictors)\n",
    "#predictors.remove(\"instant\")\n",
    "predictors.remove(\"dteday\")\n",
    "#predictors.remove(\"hr\")\n",
    "predictors.remove(\"casual\")\n",
    "predictors.remove(\"registered\")\n",
    "predictors.remove(\"cnt\")\n",
    "print(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17466.1359432\n",
      "132.159509469\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train[predictors], train[\"cnt\"])\n",
    "predictions = lr.predict(test[predictors])\n",
    "lr_mse = mean_squared_error(test[\"cnt\"], predictions)\n",
    "print(lr_mse)\n",
    "lr_rmse = lr_mse**(0.5)\n",
    "print(lr_rmse)\n",
    "\n",
    "#lr_auc = roc_auc_score(test[\"cnt\"], predictions)\n",
    "#print(lr_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error\n",
    "The error is very high, which may be due to the fact that the data has a few extremely high rental counts, but otherwise mostly low counts. Larger errors are penalized more with MSE, which leads to a higher total error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Applying Decision Trees\n",
    "Now we will apply the decision tree algorithm. We will be able to compare its error with the error from linear regression, which will enable us to pick the right algorithm for this data set.\n",
    "\n",
    "* Use the `DecisionTreeRegressor` class to fit a decision tree algorithm to the `train` data.\n",
    "* Make predictions using the `DecisionTreeRegressor` class on `test`.\n",
    "* Calculate the error between the predictions and the actual values.\n",
    "* Experiment with various parameters of the `DecisionTreeRegressor` class, including `min_samples_leaf`, to see if it changes the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3398.95195627\n",
      "58.300531355\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(train[predictors], train[\"cnt\"])\n",
    "dt_pred = dt.predict(test[predictors])\n",
    "dt_mse = mean_squared_error(test[\"cnt\"], dt_pred)\n",
    "print(dt_mse)\n",
    "dt_rmse = dt_mse**(0.5)\n",
    "print(dt_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### varying parameter min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt 5   2514.07409016   50.1405433772\n",
      "dt 15   3020.94356497   54.963110947\n",
      "dt 25   3426.68890236   58.5379270419\n",
      "dt 35   3594.98593004   59.9582015244\n",
      "dt 45   4018.75660908   63.3936637928\n",
      "dt 55   4633.0684945   68.0666474457\n",
      "dt 65   4940.14746591   70.2861826102\n",
      "dt 75   5020.31654581   70.8541921541\n",
      "dt 85   5480.79131829   74.0323666938\n",
      "dt 95   5785.04038304   76.0594529499\n",
      "dt 105   5915.98834548   76.9154623303\n",
      "dt 115   6832.44238538   82.6585893019\n",
      "dt 125   7185.90327348   84.7697072867\n",
      "dt 135   7223.50882067   84.9912279042\n",
      "dt 145   7402.9732421   86.0405325536\n",
      "dt 155   7684.67162461   87.6622588382\n",
      "dt 165   7929.08753757   89.0454240125\n",
      "dt 175   7922.03588131   89.0058193677\n",
      "dt 185   8352.96861523   91.3945765089\n",
      "dt 195   8550.68033405   92.4698887966\n"
     ]
    }
   ],
   "source": [
    "# change parameters\n",
    "for i in range(5,200,10):\n",
    "    dt = DecisionTreeRegressor(min_samples_leaf = i)\n",
    "    dt.fit(train[predictors], train[\"cnt\"])\n",
    "    dt_pred = dt.predict(test[predictors])\n",
    "    dt_mse = mean_squared_error(test[\"cnt\"], dt_pred)\n",
    "    dt_rmse = dt_mse**(0.5)\n",
    "    print(\"dt\", i, \" \", dt_mse, \" \", dt_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with min_samples_leaf = 5 gives the least error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### varying parameter min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt 10   2831.17313367   53.2087693305\n",
      "dt 20   2699.47657568   51.95648733\n",
      "dt 30   2747.46211785   52.4162390663\n",
      "dt 40   2795.35171786   52.8710858396\n",
      "dt 50   2913.10408569   53.973179318\n",
      "dt 60   3055.35537964   55.2752691503\n",
      "dt 70   3132.60266618   55.9696584426\n",
      "dt 80   3151.50044208   56.1382262107\n",
      "dt 90   3314.06729962   57.5679363849\n",
      "dt 100   3411.63234711   58.4091803325\n",
      "dt 110   3593.68667102   59.9473658389\n",
      "dt 120   3697.66886315   60.808460457\n",
      "dt 130   4110.31735237   64.1117567406\n",
      "dt 140   4172.16342204   64.5922860877\n",
      "dt 150   4227.35106748   65.0180826192\n",
      "dt 160   4400.1899671   66.3339277226\n",
      "dt 170   4503.09238699   67.1050846582\n",
      "dt 180   4679.07782906   68.4037851954\n",
      "dt 190   4695.15717171   68.5212169457\n"
     ]
    }
   ],
   "source": [
    "# change parameters\n",
    "for i in range(10,200,10):\n",
    "    dt = DecisionTreeRegressor(min_samples_split = i)\n",
    "    dt.fit(train[predictors], train[\"cnt\"])\n",
    "    dt_pred = dt.predict(test[predictors])\n",
    "    dt_mse = mean_squared_error(test[\"cnt\"], dt_pred)\n",
    "    dt_rmse = dt_mse**(0.5)\n",
    "    print(\"dt\", i, \" \", dt_mse, \" \", dt_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with min_samples_split = 20 gives the least error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### varying parameter max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt 2   18703.5870359   136.761058185\n",
      "dt 3   15941.4719162   126.259541882\n",
      "dt 4   13796.2534346   117.457453721\n",
      "dt 5   11786.2661442   108.564571312\n",
      "dt 6   10104.0067848   100.518688734\n",
      "dt 7   7217.9131271   84.9583022847\n",
      "dt 8   5657.42829392   75.2158779376\n",
      "dt 9   4260.0728701   65.2692337177\n",
      "dt 10   3405.99812258   58.3609297611\n",
      "dt 11   3136.51111261   56.0045633195\n",
      "dt 12   3098.79209144   55.6667952323\n",
      "dt 13   3083.25195731   55.5270380743\n",
      "dt 14   3139.22239926   56.0287640347\n",
      "dt 15   3222.46007095   56.7667162248\n",
      "dt 16   3096.73771871   55.648339766\n",
      "dt 17   3309.74924485   57.5304201693\n",
      "dt 18   3373.73058046   58.0838237417\n",
      "dt 19   3409.62157304   58.3919649699\n"
     ]
    }
   ],
   "source": [
    "# change parameters\n",
    "for i in range(2,20):\n",
    "    dt = DecisionTreeRegressor(max_depth = i)\n",
    "    dt.fit(train[predictors], train[\"cnt\"])\n",
    "    dt_pred = dt.predict(test[predictors])\n",
    "    dt_mse = mean_squared_error(test[\"cnt\"], dt_pred)\n",
    "    dt_rmse = dt_mse**(0.5)\n",
    "    print(\"dt\", i, \" \", dt_mse, \" \", dt_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with max_depth = 13 gives the least error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### varying parameter min_samples_split while keeping max_depth at 13 and min_samples_leaf at 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt 1   2552.6837062   50.524090355\n",
      "dt 2   2562.88524378   50.6249468521\n",
      "dt 3   2563.64794297   50.6324791312\n",
      "dt 4   2545.62704361   50.4542073925\n",
      "dt 5   2545.77093998   50.455633382\n",
      "dt 6   2551.79019356   50.5152471394\n",
      "dt 7   2555.01224099   50.5471289095\n",
      "dt 8   2551.01838086   50.5076071583\n",
      "dt 9   2561.2446204   50.6087405534\n",
      "dt 10   2550.01295443   50.4976529596\n",
      "dt 11   2543.44764169   50.4326049465\n",
      "dt 12   2522.49512544   50.2244474876\n",
      "dt 13   2550.97825616   50.5072099423\n",
      "dt 14   2550.37216533   50.5012095432\n",
      "dt 15   2579.21758962   50.7859979682\n",
      "dt 16   2606.53083234   51.0541950513\n",
      "dt 17   2611.73586806   51.105145221\n",
      "dt 18   2619.78551303   51.1838403505\n",
      "dt 19   2609.70413387   51.0852633728\n",
      "dt 20   2581.58548572   50.8093051096\n",
      "dt 21   2586.61935115   50.8588178308\n",
      "dt 22   2589.23740085   50.8845497263\n",
      "dt 23   2577.03511042   50.7645064038\n",
      "dt 24   2572.42276242   50.7190571918\n",
      "dt 25   2577.487631   50.768963265\n",
      "dt 26   2584.77324313   50.8406652507\n",
      "dt 27   2586.39926572   50.8566540948\n",
      "dt 28   2627.16836025   51.2559104909\n",
      "dt 29   2640.2055127   51.3829301685\n",
      "dt 30   2677.19897427   51.7416560835\n",
      "dt 31   2683.70919343   51.8045286962\n",
      "dt 32   2695.99602166   51.922981633\n",
      "dt 33   2683.36463423   51.8012030192\n",
      "dt 34   2669.43701203   51.66659474\n",
      "dt 35   2690.00544445   51.8652624061\n",
      "dt 36   2711.07247596   52.0679601671\n",
      "dt 37   2741.23956182   52.35684828\n",
      "dt 38   2747.12508504   52.413024002\n",
      "dt 39   2765.84616598   52.5913126475\n",
      "dt 40   2781.51605814   52.740080187\n",
      "dt 41   2784.51087915   52.7684648171\n",
      "dt 42   2796.29698093   52.8800244037\n",
      "dt 43   2798.16587527   52.8976925326\n",
      "dt 44   2814.10014985   53.0480928012\n",
      "dt 45   2825.50145282   53.1554461257\n",
      "dt 46   2816.28949032   53.0687242198\n",
      "dt 47   2898.73593406   53.8399102345\n",
      "dt 48   2919.11897282   54.0288716597\n",
      "dt 49   2916.45352737   54.0041991643\n"
     ]
    }
   ],
   "source": [
    "# change parameters\n",
    "for i in range(1,50,1):\n",
    "    dt = DecisionTreeRegressor(max_depth = 13, min_samples_leaf = 5, min_samples_split = i)\n",
    "    dt.fit(train[predictors], train[\"cnt\"])\n",
    "    dt_pred = dt.predict(test[predictors])\n",
    "    dt_mse = mean_squared_error(test[\"cnt\"], dt_pred)\n",
    "    dt_rmse = dt_mse**(0.5)\n",
    "    print(\"dt\", i, \" \", dt_mse, \" \", dt_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with max_depth = 13, min_samples_leaf = 12 and min_samples_split = 12 gives the least error **_2522.49512544_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6: Applying Random Forests\n",
    "We can now apply the random forest algorithm, which improves on the decision tree algorithm. \n",
    "\n",
    "* Use the `RandomForestRegressor` class to fit a random forest algorithm to the `train` data.\n",
    "* Make predictions using the `RandomForestRegressor` class on `test`.\n",
    "* Calculate the error between the predictions and the actual values.\n",
    "* Experiment with various parameters of the `RandomForestRegressor` class, including `min_samples_leaf`, to see if it changes the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "reg = RandomForestRegressor()\n",
    "reg.fit(train[predictors], train[\"cnt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014.60956559264"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = reg.predict(test[predictors])\n",
    "numpy.mean((predictions - test[\"cnt\"]) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest model gives lower error than the Decision Tree models.\n",
    "**_2014.60956559264_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### varying parameter min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg 1   1924.91687572   43.8738746376\n",
      "reg 2   1858.47258055   43.1100055736\n",
      "reg 3   1972.86201647   44.4169113793\n",
      "reg 4   1934.87263184   43.9871871327\n",
      "reg 5   1956.36120737   44.2307721769\n",
      "reg 6   1944.59206259   44.0975289851\n",
      "reg 7   2006.70309854   44.7962397812\n",
      "reg 8   1998.02247759   44.6992447094\n",
      "reg 9   1939.96530615   44.0450372477\n",
      "reg 10   1930.4370085   43.9367387103\n",
      "reg 11   1971.14211324   44.3975462525\n",
      "reg 12   2019.85212879   44.9427650328\n",
      "reg 13   2002.63291918   44.7507867996\n",
      "reg 14   2016.34718507   44.9037546879\n",
      "reg 15   2072.02089014   45.5194561714\n",
      "reg 16   1955.42416832   44.2201782936\n",
      "reg 17   2065.98902812   45.4531520152\n",
      "reg 18   2150.8606843   46.3773725463\n",
      "reg 19   2136.85957127   46.2261784194\n",
      "reg 20   2166.16971667   46.5421284072\n",
      "reg 21   2140.42660449   46.2647447252\n",
      "reg 22   2153.69453912   46.4079146172\n",
      "reg 23   2172.63210057   46.6115018056\n",
      "reg 24   2116.01361416   46.0001479798\n"
     ]
    }
   ],
   "source": [
    "# change parameters\n",
    "for i in range(1,25,1):\n",
    "    reg = RandomForestRegressor(max_depth = None, min_samples_leaf = 1, min_samples_split = i)\n",
    "    reg.fit(train[predictors], train[\"cnt\"])\n",
    "    reg_pred = reg.predict(test[predictors])\n",
    "    reg_mse = mean_squared_error(test[\"cnt\"], reg_pred)\n",
    "    reg_rmse = reg_mse**(0.5)\n",
    "    print(\"reg\", i, \" \", reg_mse, \" \", reg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with min_samples_split = 2 gives the least error **_1858.47258055_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### varying parameter min_samples_leaf while keeping max_depth at None and min_samples_split at 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg 1   1954.10769275   44.2052903254\n",
      "reg 2   1879.65091012   43.3549410116\n",
      "reg 3   1980.39693055   44.5016508744\n",
      "reg 4   1945.66298678   44.1096699918\n",
      "reg 5   2038.08128718   45.1451136578\n",
      "reg 6   2069.72232426   45.494200996\n",
      "reg 7   2206.85959965   46.977224265\n",
      "reg 8   2213.40290722   47.0468161221\n",
      "reg 9   2256.47419986   47.5023599399\n",
      "reg 10   2305.56056261   48.0162531088\n",
      "reg 11   2365.75298141   48.6390067889\n",
      "reg 12   2545.72446487   50.4551728257\n",
      "reg 13   2548.68575208   50.4845100212\n",
      "reg 14   2637.54673651   51.3570514779\n",
      "reg 15   2542.42934985   50.4225083653\n",
      "reg 16   2759.3525602   52.5295398819\n",
      "reg 17   2659.40867743   51.5694548879\n",
      "reg 18   2901.29493321   53.8636698825\n",
      "reg 19   2884.72352552   53.7096222806\n",
      "reg 20   2821.45124628   53.1173347061\n",
      "reg 21   2884.45160813   53.7070908552\n",
      "reg 22   3112.21795422   55.787256199\n",
      "reg 23   2944.92767809   54.2671878587\n",
      "reg 24   3021.70618108   54.970048036\n"
     ]
    }
   ],
   "source": [
    "# change parameters\n",
    "for i in range(1,25,1):\n",
    "    reg = RandomForestRegressor(max_depth = None, min_samples_leaf = i, min_samples_split = 2)\n",
    "    reg.fit(train[predictors], train[\"cnt\"])\n",
    "    reg_pred = reg.predict(test[predictors])\n",
    "    reg_mse = mean_squared_error(test[\"cnt\"], reg_pred)\n",
    "    reg_rmse = reg_mse**(0.5)\n",
    "    print(\"reg\", i, \" \", reg_mse, \" \", reg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with min_samples_leaf = 2 gives the least error **_1879.65091012_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg 49   1855.81068028   43.0791211642\n"
     ]
    }
   ],
   "source": [
    "reg = RandomForestRegressor(max_depth = None, min_samples_leaf = 2, min_samples_split = 3)\n",
    "reg.fit(train[predictors], train[\"cnt\"])\n",
    "reg_pred = reg.predict(test[predictors])\n",
    "reg_mse = mean_squared_error(test[\"cnt\"], reg_pred)\n",
    "reg_rmse = reg_mse**(0.5)\n",
    "print(\"reg\", i, \" \", reg_mse, \" \", reg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varying the parameters helps lower the error even further to under 1900."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
